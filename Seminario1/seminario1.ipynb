{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminario1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYnIJGf_FpiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV9WbVAZFpig",
        "colab_type": "text"
      },
      "source": [
        "# Seminario 1 : Aprender a construir redes neuronales simples\n",
        "\n",
        "###Autores: \n",
        "\n",
        "Jose Sanchez, josangar.sg@gmail.com\n",
        "\n",
        "Rafael López, lopgon.rafael@gmail.com\n",
        "\n",
        "---\n",
        "\n",
        "support: seminarios.ai.soporte@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvLHz7t3Mnr4",
        "colab_type": "text"
      },
      "source": [
        "##Estructura del seminario\n",
        "\n",
        "1. Definición de requisitos\n",
        "2. Estructura de un proyecto de Deep Learning\n",
        "3. Construcción de una red neuronal fully connected mediante Keras\n",
        "4. Construcción de una red neuronal convolucional mediante Keras\n",
        "5. Caso práctico\n",
        "6. Conclusiones\n",
        "7. Configuración del entorno de trabajo local\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sKNg7KnV_Cl",
        "colab_type": "text"
      },
      "source": [
        "## 1. Definición de requisitos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot-zCUtkFpii",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Requisitos de software\n",
        "\n",
        "#### Lenguaje de programación: \n",
        "  - Python 3.6\n",
        "  \n",
        "### Librerías:\n",
        "  - **Tensorflow**: es una librería de software de código abierto para computación numérica, que utiliza gráficos de flujo de datos.\n",
        "  \n",
        "  - **Keras**: es un framework de alto nivel para el aprendizaje, escrito en Python y capaz de correr sobre los frameworks TensorFlow, CNTK, o Theano. Fue desarrollado con el objeto de facilitar un proceso de experimentación rápida.\n",
        "  \n",
        "  - **NumPy**: es una librería de Python, que le agrega mayor soporte para vectores y matrices, constituyendo una biblioteca de funciones matemáticas de alto nivel para operar con esos vectores o matrices.\n",
        "  \n",
        "  - **Matplotlib**: es una librería para la generación de gráficos a partir de datos contenidos en listas o arrays en el lenguaje de programación Python y su extensión matemática NumPy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_J4_7_TOZsF",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Requisitos de datos\n",
        "\n",
        "MNIST es un conjunto de datos de imagen público que consta de una imagen de 28 por 28 píxeles de un solo dígito escrita a mano. Cada imagen en MNIST es un dígito del 0 al 9. El desafío del MNIST es desarrollar un algoritmo de aprendizaje automático que pueda clasificar estas imágenes en 10 clases (0 a 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bux2E0I0TcYH",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/dataset.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nU4pf0AFpij",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Importación de dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3f-prXsFpik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (10,10)\n",
        "\n",
        "from keras.datasets import mnist # Dataset a utilizar\n",
        "from keras.models import Model # Modelo sobre el que se definen las redes neuronales\n",
        "from keras.layers import Input, Dense, Dropout # Capas red fully connected\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten # Capas red para convolucional\n",
        "from keras.utils import np_utils # Utilidades para procesar datos\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ovGYnoDTpG2",
        "colab_type": "text"
      },
      "source": [
        "## 2. Estructura de un proyecto de Deep Learning\n",
        "\n",
        "- Preparación del dataset\n",
        "- Carga de datos\n",
        "- Diseño de la arquitectura de la red neuronal\n",
        "- Entrenamiento\n",
        "- Evaluación del modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yb15Ev2XLgk",
        "colab_type": "text"
      },
      "source": [
        "## 3. Construcción de una red neuronal fully connected mediante Keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQvJG7FRU334",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/mnist.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-ksR5zVFpip",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xanXt5O7Fpiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_classes = 10\n",
        "\n",
        "# the data, shuffled and split between tran and test sets\n",
        "(X_train, y_train), (X_testval, y_testval) = mnist.load_data()\n",
        "print(\"X_train original shape\", X_train.shape)\n",
        "print(\"y_train original shape\", y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vif0_Wr6X2-c",
        "colab_type": "text"
      },
      "source": [
        "#### Visualización de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC7zz21TFpiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDzSxxKdFpiy",
        "colab_type": "text"
      },
      "source": [
        "#### Preproceso de datos\n",
        "\n",
        "- Reshape de la imagenes (2D) a vectores (1D)\n",
        "- Convertir tipo de datos a coma flotante\n",
        "- Normalización de rangos de intensidad de las imágenes a 0-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gllZpaDFFpiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 784)\n",
        "X_testval = X_testval.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_testval = X_testval.astype('float32')\n",
        "X_train /= 255\n",
        "X_testval /= 255\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_testval.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJaNAubmFpi4",
        "colab_type": "text"
      },
      "source": [
        "#### Preproceso de etiquetas\n",
        "\n",
        "- One-hot-encoding\n",
        "\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "etc.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlrS_SzyFpi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Y_train from 0 to 9')\n",
        "print(y_train[:10])\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_testval = np_utils.to_categorical(y_testval, nb_classes)\n",
        "print('Y_train onehot encoding')\n",
        "print(Y_train[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iwalwzO2cD7",
        "colab_type": "text"
      },
      "source": [
        "#### Partición de datos de test en subset de validación y subset de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS0U-wVB2tE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = X_testval[:int(X_testval.shape[0]/2)]\n",
        "Y_val = Y_testval[:int(Y_testval.shape[0]/2)]\n",
        "X_test = X_testval[int(X_testval.shape[0]/2):]\n",
        "Y_test = Y_testval[int(Y_testval.shape[0]/2):]\n",
        "y_test = np.argmax(Y_test, axis=1)\n",
        "print(\"Validation matrix shape\", X_val.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb3UrxLesqUg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 3.2 Diseño de la arquitectura de la red neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrcU4TJPFpi7",
        "colab_type": "text"
      },
      "source": [
        "Hoy en día, la mayoría de los científicos nos advierten que deberíamos tener cuidado con esta analogía, ya que las redes neuronales fueron diseñadas para resolver problemas de aprendizaje de máquinas (en inglés, machine learning) y no para representar el cerebro con precisión. Sin embargo, la idea de que una neurona biológica simplificada representa la unidad central de una red neuronal es una metáfora que ha perdurado a través de las décadas. La progresión de las neuronas biológicas a las neuronas artificiales se puede resumir con la siguiente gráfica.\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/neuron-anatomy.jpg)\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/neuron-simple.jpg)\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/diagrama_neurona.PNG)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "La entrada a un regressor o un clasificador lineal tiene la forma: \n",
        "\n",
        "                                   f(X)=b+∑wi*xi\n",
        "                                   \n",
        "Donde la clasificación sería:\n",
        "- 1 si f(X)>0\n",
        "- 0 si f(X)<=0\n",
        "\n",
        "Podemos interpretar que cada peso, wi, representa la influencia relativa de la entrada por la cual se multiplica, xi. A menudo al término b se le llama sesgo (en inglés bias), ya que controla qué tan predispuesta está la neurona a disparar un 1 o un 0 independiente de los pesos. Un sesgo alto hace que la neurona requiera una entrada más alta para generar una salida de 1. Un sesgo bajo lo hace más fácil.\n",
        "\n",
        "\n",
        "Se puede obtener una verdadera red neuronal a partir de esta fórmula si introducimos dos inovaciones. La primera es la adición de una función de activación, la cual transforma nuestra discirimador lineal en lo que se llama una neurona, o “unidad” (para disociarlo de analogías del cerebro). La segunda inovación consiste en organizar las neuronas de una manera particular: una arquitectura de neuronas conectadas secuencialmente en capas. \n",
        "\n",
        "Tanto en las redes neuronales artificiales como biológicas, una neurona no sólo transmite la entrada que recibe. Existe un paso adicional, una función de activación, que es análoga a la tasa de potencial de acción disparando en el cerebro. La función de activación utiliza la misma suma ponderada de la entrada anterior, \n",
        "\n",
        "                                        z= b+∑wi*xi, \n",
        "\n",
        "y la transforma una vez más como salida.\n",
        "\n",
        "La mayoría de las redes neuronales actuales usan otro tipo de función de activación llamada rectified linear unit o ReLU. A pesar del nombre complicado, se define simplemente como \n",
        "\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/relu.png)\n",
        "\n",
        "\n",
        "Las ReLUs permiten el paso de todos los valores positivos sin cambiarlos, pero asigna todos los valores negativos a 0. Aunque existen funciones de activación aún más recientes, la mayoría de las redes neuronales de hoy utilizan ReLU o una de sus variantes.\n",
        "\n",
        "Independiente de la función de activación que utilizemos, podemos visualizar una neurona individual con el siguiente diagrama, una visual representativa e intuitiva del comportamiento de una neurona.\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/diagrama_neurona.PNG)\n",
        "\n",
        "Ahora que hemos descrito una neurona, podemos definir una red neuronal. Una red neuronal consiste en una serie de capas de neuronas. Específicamente, todas las neuronas de una capa se conectan a las neuronas de la siguiente capa.\n",
        "\n",
        "Un detalle es que cuanto contamos el número de capas en una red neuronal, sólo contamos las capas con entradas (omitimos la primera capa de entrada). La figura anterior representa una red neuronal de 2 capas con 1 capa oculta. Contiene 3 neuronas de entrada, 2 neuronas en la capa oculta, y 1 neurona de salida.\n",
        "\n",
        "Otra manera de interpretar esta idea es que las capas ocultas representan “características” a nivel superior o atributos de nuestros datos. Cada una de las neuronas de una capa oculta sopesa sus entradas de forma diferente, y de esta manera aprende características diferentes de los datos. Nuestra neurona de salida logra capturar estas características intermediarias, no sólo las entradas originales. Al incluir más de una capa oculta, permitimos que la red neuronal pueda aprender sobre varios niveles de abstracción de los datos.\n",
        "\n",
        "Si encadenamos múltiples transformaciones no lineales a través de las capas, aumentamos la flexibilidad y capacidad de expresión de la red neuronal. Aunque la prueba es compleja y mucho más avanzada de lo que podemos cubrir en este seminario, se puede demostrar que cualquier red neuronal de 2 capas con una función de activación no lineal (incluyendo la sigmoide o ReLU) y con suficientes neuronas ocultas es un aproximador de función universal (en inglés, universal function approximator), es decir teóricamente es capaz de expresar cualquier mapeo arbitrario de entrada-a-salida. Las redes neuronales son poderosas precisamente por esta propiedad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "813o2L5VszDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=(X_train.shape[1],)) # Declaramos las dimensionesde los datos de entrada a la red\n",
        "hidden_layer = Dense(32, activation='relu')(input_layer) # Definimos una capa oculta y su función de activación\n",
        "output_layer = Dense(10, activation='softmax')(hidden_layer) # Definimos la capa de salida y su función de activación\n",
        "model= Model(inputs=input_layer, outputs=output_layer) # Generamos el modelo de keras a partir de las capas que hemos definido\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXTlK0dtFpi_",
        "colab_type": "text"
      },
      "source": [
        "#### Compilación del modelo\n",
        "Keras está construido sobre Tensorflow, el cuál permite definir un grafo de computación en Python que posteriormente se compila y se lanza de forma eficiente en la CPU (o GPU) sin utilizar el intérprete de Python.\n",
        "\n",
        "Cuando se compila un modelo, debemos especificar la función de coste y el optimizador:\n",
        " \n",
        "- **Función de coste**: define como se mide el error de la red en función de las diferencias entre las predicciones de la red y las etiquetas de los datos de entrenamiento.\n",
        "- **Optimizador**: determina como aprende el modelo, es decir, como se propaga el error a la salida de la red por las diferentes capas de la misma. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-FnU0EHFpjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3aTL7sFFpjC",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Entrenamiento\n",
        "\n",
        "- Definir batch_size\n",
        "- Definir número de epochs (iteraciones de entrenamiento)\n",
        "- Intruducir datos para la validación del entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYoK3AjlFpjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128, nb_epoch=4,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncHoAyNBFpjH",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Evaluación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS6lkWLT4RyT",
        "colab_type": "text"
      },
      "source": [
        "#### Obtención de métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wk2Q_YGFpjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXbjwWDeFpjL",
        "colab_type": "text"
      },
      "source": [
        "#### Inspección de las predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2go-gfGjFpjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predecimos las clases de los datos de test y las post-procesamos para trabajar\n",
        "# cómodament con ellas\n",
        "predicted_classes = model.predict(X_test)\n",
        "predicted_classes = np.round(predicted_classes)\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)\n",
        "\n",
        "# Obtenemos los índices de las muestras que se han predecido correcta e \n",
        "# incorrectamente para mostrarlas posteriomente\n",
        "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
        "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjR5EdF8FpjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostramos muestras correctamente clasificadas\n",
        "plt.figure()\n",
        "for i, correct in enumerate(correct_indices[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w5LsnITctHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostramos muestras incorrectamente clasificadas\n",
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0UenxhbdFU_",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Añadiendo complejidad al modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRQ1qUL4d7Ys",
        "colab_type": "text"
      },
      "source": [
        "#### Añadir más neuronas a la capa oculta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K52KJtdpd5s8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Diseño de la arquitectura de la red neuronal\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "hidden_layer = Dense(512, activation='relu')(input_layer)\n",
        "output_layer = Dense(10, activation='softmax')(hidden_layer)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128, nb_epoch=4,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val)\n",
        "         )\n",
        "\n",
        "# Obtención de métricas\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg2SQKzifFha",
        "colab_type": "text"
      },
      "source": [
        "#### Añadir más capas ocultas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sqlzZUUfRQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Diseño de la arquitectura de la red neuronal\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "hidden_layer_1 = Dense(512, activation='relu')(input_layer)\n",
        "hidden_layer_2 = Dense(512, activation='relu')(hidden_layer_1)\n",
        "output_layer = Dense(10, activation='softmax')(hidden_layer_2)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128, nb_epoch=4,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val)\n",
        "         )\n",
        "\n",
        "# Obtención de métricas\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEg94tysf4f9",
        "colab_type": "text"
      },
      "source": [
        "#### Añadimos dropout para evitar overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0Hq57zfgAn8",
        "colab_type": "text"
      },
      "source": [
        "Es muy común que al comenzar a aprender machine learning caigamos en el problema del Overfitting. Lo que ocurrirá es que nuestra máquina sólo se ajustará a aprender los casos particulares que le enseñamos y será incapaz de reconocer nuevos datos de entrada. \n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/overfitting.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-clsmyfgTOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Diseño de la arquitectura de la red neuronal\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "hidden_layer_1 = Dense(512, activation='relu')(input_layer)\n",
        "dropout_1 = Dropout(0.2)(hidden_layer_1)\n",
        "hidden_layer_2 = Dense(512, activation='relu')(hidden_layer_1)\n",
        "dropout_2 = Dropout(0.2)(hidden_layer_2)\n",
        "output_layer = Dense(10, activation='softmax')(dropout_2)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128, nb_epoch=4,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val)\n",
        "         )\n",
        "\n",
        "# Obtención de métricas\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEtDFDBqFpjV",
        "colab_type": "text"
      },
      "source": [
        "## 4. Construcción de una red neuronal convolucional mediante Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSJjG66elwKN",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/neural_network.png)\n",
        "\n",
        "La CNN es un tipo de Red Neuronal Artificial con aprendizaje supervisado que procesa sus capas imitando al cortex visual del ojo humano para identificar distintas características en las entradas que en definitiva hacen que pueda identificar objetos y «ver». Para ello, la CNN contiene varias capas ocultas especializadas y con una jerarquía: esto quiere decir que las primeras capas pueden detectar lineas, curvas y se van especializando hasta llegar a capas más profundas que reconocen formas complejas como un rostro o la silueta de un animal.\n",
        "\n",
        "Para comenzar, la red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a  784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usaríamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada. Para continuar con el ejemplo, supondremos que utilizamos la imagen con 1 sólo color.\n",
        "\n",
        "\n",
        "**Capa Convolucional**\n",
        "\n",
        "Ahora comienza el «procesado distintivo» de las CNN. Es decir, haremos las llamadas «convoluciones»: Estas consisten en tomar «grupos de pixeles cercanos» de la imagen de entrada e ir operando matemáticamente (producto escalar) contra una pequeña matriz que se llama kernel. Ese kernel supongamos de tamaño 3×3 pixels «recorre» todas las neuronas de entrada (de izquierda-derecha, de arriba-abajo) y genera una nueva matriz de salida, que en definitiva será nuestra nueva capa de neuronas ocultas.\n",
        "\n",
        "**Filtro: Conjunto de Kernels**\n",
        "\n",
        "En realidad, no aplicaremos 1 sólo kernel, si no que tendremos muchos kernel (su conjunto se llama filtros). Por ejemplo en esta primer convolución podríamos tener 32 filtros, con lo cual realmente obtendremos 32 matrices de salida (este conjunto se conoce como «feature mapping»), cada una de 28x28x1 dando un total del 25.088 neuronas para nuestra PRIMER CAPA OCULTA de neuronas.\n",
        "\n",
        "A medida que vamos desplazando el kernel y vamos obteniendo una «nueva imagen» filtrada por el kernel. En esta primer convolución y siguiendo con el ejemplo anterior, es como si obtuviéramos 32 «imágenes filtradas nuevas». Estas imágenes nuevas lo que están «dibujando» son ciertas características de la imagen original. Esto ayudará en el futuro a poder distinguir un objeto de otro.\n",
        "\n",
        "**La función de Activación**\n",
        "\n",
        "La función de activación más utilizada para este tipo de redes neuronales es la llamada ReLu\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/convolucionales.png)\n",
        "\n",
        "**Subsampling: Capa MaxPooling**\n",
        "\n",
        "Ahora viene un paso en el que reduciremos la cantidad de neuronas antes de hacer una nueva convolución. ¿Por qué? Como vimos, a partir de nuestra imagen blanco y negro de 28x28px tenemos una primer capa de entrada de 784 neuronas y luego de la primer convolución obtenemos una capa oculta de 25.088 neuronas -que realmente son nuestros 32 mapas de características de 28×28-\n",
        "\n",
        "Si hiciéramos una nueva convolución a partir de esta capa, el número de neuronas de la próxima capa se iría por las nubes (y ello implica mayor procesamiento)! Para reducir el tamaño de la próxima capa de neuronas haremos un proceso de subsampling en el que reduciremos el tamaño de nuestras imágenes filtradas pero en donde deberán prevalecer las características más importantes que detectó cada filtro.\n",
        "\n",
        "\n",
        "**Conectar con una red neuronal «tradicional».**\n",
        "\n",
        "Para terminar, tomaremos la última capa oculta a la que hicimos subsampling, que se dice que es «tridimensional» por tomar la forma -en nuestro ejemplo- 3x3x128 (alto,ancho,mapas) y la «aplanamos», esto es que deja de ser tridimensional, y pasa a ser una capa de neuronas «tradicionales», de las que ya conocíamos.\n",
        "\n",
        "Entonces, a esta nueva capa oculta «tradicional», le aplicamos una función llamada Softmax que conecta contra la capa de salida final que tendrá la cantidad de neuronas correspondientes con las clases que estamos clasificando. Si clasificamos perros y gatos, serán 2 neuronas. Si es el dataset Mnist numérico serán 10 neuronas de salida. Si clasificamos coches, aviones ó barcos serán 3, etc.\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/Typical_cnn.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP5PlGXWhs2d",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiswcDaJh2Kk",
        "colab_type": "text"
      },
      "source": [
        "#### Preproceso de datos\n",
        "- Reshape a tamaño 28x28x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQddDs4VijgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28)[..., np.newaxis]\n",
        "X_val = X_val.reshape(X_val.shape[0], 28, 28)[..., np.newaxis]\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28)[..., np.newaxis]\n",
        "print(\"X_train dimensions\", X_train.shape)\n",
        "print(\"X_val dimensions\", X_val.shape)\n",
        "print(\"X_test dimensions\", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWSYUh9ujSCt",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Diseño de la arquitectura de la red neuronal convolucional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0XYqzyMkFcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=(X_train.shape[1],X_train.shape[2], 1))\n",
        "conv_layer_1 = Conv2D(filters=8, kernel_size=(3, 3), activation='relu')(input_layer)\n",
        "maxpool_layer_1 = MaxPool2D(pool_size=(2, 2))(conv_layer_1)\n",
        "conv_layer_2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(maxpool_layer_1)\n",
        "maxpool_layer_2 = MaxPool2D(pool_size=(2, 2))(conv_layer_2)\n",
        "conv_layer_3 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(maxpool_layer_2)\n",
        "flatten_layer = Flatten()(conv_layer_3)\n",
        "dense_layer = Dense(128, activation='relu')(flatten_layer)\n",
        "output_layer = Dense(10, activation='softmax')(dense_layer)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSreIU-rm3wp",
        "colab_type": "text"
      },
      "source": [
        "#### Compilación\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNl1dAX-m_MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWkV8M1nnBD7",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MlQ-2fsnIQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128, nb_epoch=4,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-64MFHKWomZg",
        "colab_type": "text"
      },
      "source": [
        "### 4.4 Evaluación del modelo\n",
        "\n",
        "#### Obtención de métricas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIA30irCozcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLS1RJ6-3EbO",
        "colab_type": "text"
      },
      "source": [
        "## 5. Caso práctico\n",
        "\n",
        "Diseñar un modelo adecuado capaz de clasificar el dataset CIFAR 10, disponible en keras.\n",
        "\n",
        "###CIFAR 10\n",
        "\n",
        "Este es un dataset de 50000 imagenes a color etiquetadas en 10 categorías diferentes. Cuenta con 10000 imagenes para test.\n",
        "\n",
        "Las clases a predecir son:\n",
        "\n",
        "- airplane \n",
        "- automobile \n",
        "- bird \n",
        "- cat \n",
        "- deer \n",
        "- dog \n",
        "- frog \n",
        "- horse \n",
        "- ship \n",
        "- truck\n",
        "\n",
        "\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/cifar_preview.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxAGnZ4p5Kcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10 # Dataset a utilizar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5nImPqdc1vQ",
        "colab_type": "text"
      },
      "source": [
        "##6. Conclusiones\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/josangar/Curso_Deep_Learning/master/Seminario1/images/comparativa.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w-lptui8l2_",
        "colab_type": "text"
      },
      "source": [
        "##7. Configuración del entorno local de trabajo\n",
        "\n",
        "Instalar:\n",
        "\n",
        "- PyCharm (IDE)\n",
        "- Distribución 3.6.8 de Python (Interprete)\n",
        "- Instalar poetry (gestor de librerías)\n",
        "\n",
        "Para utilizar GPU\n",
        "- Instalar CUDA 9.0 seguir este tutorial:\n",
        "https://medium.com/@akshaysin_86681/installing-cuda-and-cudnn-on-windows-10-f735585159f7\n",
        "\n",
        "1. Crear una carpeta de proyecto (repositorio GitHub/BitBucket)\n",
        "2. Abrir la carpeta en PyCharm\n",
        "3. Configurar intérprete:\n",
        "\n",
        "        File>Settings>Projects>Projects Interpreter\n",
        "\n",
        "                1. Add Python Interpreter\n",
        "                2. Virtual Environment:\n",
        "                          Location: Project\\venv\n",
        "                          Base Interpreter:select python.exe\n",
        "                  \n",
        "3. Ejecutar **poetry init (generará un venv)**\n",
        "4. Ejecutar **poetry install \"library\"** (con cada librería que queramos instalar)\n",
        "5. Ejecutar **poetry install -D iPython** (para contar con iPython solo en modo Desarrollador)\n",
        "6. Comenzar a desarrollar\n",
        "\n",
        "\n"
      ]
    }
  ]
}